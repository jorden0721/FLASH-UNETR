{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b2210a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q \"monai-weekly[nibabel, tqdm, einops]\"\n",
    "!python -c \"import matplotlib\" || pip install -q matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b1b971b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 1.1.0\n",
      "Numpy version: 1.21.6\n",
      "Pytorch version: 1.13.1+cu117\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
      "MONAI rev id: a2ec3752f54bfc3b40e7952234fbeb5452ed63e3\n",
      "MONAI __file__: /home/user/anaconda3/envs/kevin/lib/python3.7/site-packages/monai/__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "Nibabel version: 4.0.2\n",
      "scikit-image version: 0.19.3\n",
      "Pillow version: 9.4.0\n",
      "Tensorboard version: 2.11.2\n",
      "gdown version: 4.7.1\n",
      "TorchVision version: 0.14.1+cu117\n",
      "tqdm version: 4.65.0\n",
      "lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "psutil version: 5.9.0\n",
      "pandas version: 1.3.5\n",
      "einops version: 0.6.1\n",
      "transformers version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "mlflow version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "pynrrd version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from monai.losses import DiceCELoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    EnsureChannelFirstd,#unetr\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandFlipd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    RandShiftIntensityd,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    RandRotate90d,\n",
    "    EnsureTyped,\n",
    ")\n",
    "\n",
    "from monai.config import print_config\n",
    "from monai.metrics import DiceMetric,SurfaceDiceMetric,compute_surface_dice,SurfaceDistanceMetric\n",
    "from monai.networks.nets import SwinUNETR\n",
    "\n",
    "from monai.data import (\n",
    "    ThreadDataLoader,\n",
    "    CacheDataset,\n",
    "    load_decathlon_datalist,\n",
    "    decollate_batch,\n",
    "    set_track_meta,\n",
    ")\n",
    "\n",
    "import logging\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "import torch\n",
    "\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00497c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/tmpg7_u3hy_\n"
     ]
    }
   ],
   "source": [
    "directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
    "root_dir = tempfile.mkdtemp() if directory is None else directory\n",
    "print(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d0e7a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            pixdim=(1.5, 1.5, 2.0),\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"image\"],\n",
    "            a_min=-175,\n",
    "            a_max=250,\n",
    "            b_min=0.0,\n",
    "            b_max=1.0,\n",
    "            clip=True,\n",
    "        ),\n",
    "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "        RandCropByPosNegLabeld(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            label_key=\"label\",\n",
    "            spatial_size=(96, 96, 96),\n",
    "            pos=1,\n",
    "            neg=1,\n",
    "            num_samples=4,\n",
    "            image_key=\"image\",\n",
    "            image_threshold=0,\n",
    "        ),\n",
    "        RandFlipd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            spatial_axis=[0],\n",
    "            prob=0.10,\n",
    "        ),\n",
    "        RandFlipd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            spatial_axis=[1],\n",
    "            prob=0.10,\n",
    "        ),\n",
    "        RandFlipd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            spatial_axis=[2],\n",
    "            prob=0.10,\n",
    "        ),\n",
    "        RandRotate90d(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            prob=0.10,\n",
    "            max_k=3,\n",
    "        ),\n",
    "        RandShiftIntensityd(\n",
    "            keys=[\"image\"],\n",
    "            offsets=0.10,\n",
    "            prob=0.50,\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            pixdim=(1.5, 1.5, 2.0),\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        ScaleIntensityRanged(keys=[\"image\"], a_min=-175, a_max=250, b_min=0.0, b_max=1.0, clip=True),\n",
    "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad5900c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Swin UNETR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ee66130",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████████████████████| 80/80 [02:05<00:00,  1.56s/it]\n",
      "Loading dataset: 100%|██████████████████████████| 20/20 [00:35<00:00,  1.78s/it]\n"
     ]
    }
   ],
   "source": [
    "#pretrain on word\n",
    "data_dir = \"/home/user/Documents/unetr/research-contributions/UNETR/BTCV/dataset/dataset1/\"\n",
    "split_json = \"dataset_0.json\"\n",
    "\n",
    "datasets = data_dir + split_json\n",
    "datalist = load_decathlon_datalist(datasets, True, \"training\")\n",
    "val_files = load_decathlon_datalist(datasets, True, \"validation\")\n",
    "train_ds = CacheDataset(\n",
    "    data=datalist,\n",
    "    transform=train_transforms,\n",
    "    cache_num=80,#24\n",
    "    cache_rate=1.0,\n",
    "    num_workers=4,\n",
    ")\n",
    "train_loader = ThreadDataLoader(train_ds, num_workers=20, batch_size=1, shuffle=True)\n",
    "val_ds = CacheDataset(data=val_files, transform=val_transforms, cache_num=20, cache_rate=1.0, num_workers=4)\n",
    "val_loader = ThreadDataLoader(val_ds, num_workers=0, batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4755cfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = SwinUNETR(\n",
    "    img_size=(96, 96, 96),\n",
    "    in_channels=1,\n",
    "    out_channels=8,\n",
    "    feature_size=48,\n",
    "    use_checkpoint=True,\n",
    ").to(device)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "loss_function = DiceCELoss(to_onehot_y=True, softmax=True)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9027426",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MICCAI 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73ee5001",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████████████████████| 24/24 [00:20<00:00,  1.15it/s]\n",
      "Loading dataset: 100%|████████████████████████████| 6/6 [00:04<00:00,  1.33it/s]\n"
     ]
    }
   ],
   "source": [
    "#avg 5 fold\n",
    "data_dir = \"/home/user/Documents/unetr/research-contributions/UNETR/BTCV/dataset/dataset0/\"\n",
    "# split_json = \"dataset_avg.json\"\n",
    "split_json = \"dataset_1.json\"\n",
    "datasets = data_dir + split_json\n",
    "datalist = load_decathlon_datalist(datasets, True, \"training\")\n",
    "val_files = load_decathlon_datalist(datasets, True, \"validation\")\n",
    "train_ds = CacheDataset(\n",
    "    data=datalist,\n",
    "    transform=train_transforms,\n",
    "    cache_num=24,#24\n",
    "    cache_rate=1.0,\n",
    "    num_workers=4,\n",
    ")\n",
    "train_loader = ThreadDataLoader(train_ds, num_workers=0, batch_size=1, shuffle=True)\n",
    "val_ds = CacheDataset(data=val_files, transform=val_transforms, cache_num=6, cache_rate=1.0, num_workers=4)\n",
    "val_loader = ThreadDataLoader(val_ds, num_workers=0, batch_size=1)\n",
    "\n",
    "# as explained in the \"Setup transforms\" section above, we want cached training images to not have metadata, and validations to have metadata\n",
    "# the EnsureTyped transforms allow us to make this distinction\n",
    "# on the other hand, set_track_meta is a global API; doing so here makes sure subsequent transforms (i.e., random transforms for training)\n",
    "# will be carried out as Tensors, not MetaTensors\n",
    "set_track_meta(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b030b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = SwinUNETR(\n",
    "    img_size=(96, 96, 96),\n",
    "    in_channels=1,\n",
    "    out_channels=8,\n",
    "    feature_size=48,\n",
    "    use_checkpoint=True,\n",
    ").to(device)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "loss_function = DiceCELoss(to_onehot_y=True, softmax=True)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27f50ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iterations = 25000\n",
    "eval_num = 500#500\n",
    "post_label = AsDiscrete(to_onehot=8)\n",
    "post_pred = AsDiscrete(argmax=True, to_onehot=8)\n",
    "\n",
    "dice_metric = DiceMetric(include_background=True, reduction=\"mean\", get_not_nans=False)\n",
    "dice_metric_batch=DiceMetric(include_background=True, reduction=\"mean_batch\", get_not_nans=False)\n",
    "# thresh=np.full((295,),1.0)\n",
    "nsd_metric=SurfaceDiceMetric(class_thresholds=[1.0,1.0,1.0,1.0,1.0,1.0,1.0],include_background=False,reduction=\"mean\")\n",
    "global_step = 0\n",
    "dice_val_best = 0.0\n",
    "global_step_best = 0\n",
    "epoch_loss_values = []\n",
    "metric_values = []\n",
    "import torch, gc\n",
    "def validation(epoch_iterator_val):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in epoch_iterator_val:\n",
    "            val_inputs, val_labels = (batch[\"image\"].cuda()\n",
    "                                      , batch[\"label\"].cuda())\n",
    "            val_outputs = sliding_window_inference(val_inputs, (96, 96, 96), 4, model,overlap=0.8)\n",
    "            val_labels_list = decollate_batch(val_labels)\n",
    "            val_labels_convert = [post_label(val_label_tensor) for val_label_tensor in val_labels_list]\n",
    "            val_outputs_list = decollate_batch(val_outputs)\n",
    "            val_output_convert = [post_pred(val_pred_tensor) for val_pred_tensor in val_outputs_list]\n",
    "                  \n",
    "            dice_metric(y_pred=val_output_convert, y=val_labels_convert)\n",
    "            dice_metric_batch(y_pred=val_output_convert, y=val_labels_convert)\n",
    "            \n",
    "            #NSD\n",
    "            nsd_metric(y_pred=val_output_convert[0].permute([1,0,2,3]),y=val_labels_convert[0].permute([1,0,2,3]))\n",
    "            \n",
    "            epoch_iterator_val.set_description(\"Validate (%d / %d Steps)\" % (global_step, 10.0))\n",
    "            \n",
    "            #each case dice\n",
    "#             for val_output_dice in val_output_convert:\n",
    "#                 print(\"each case dice\",torch.nanmean(dice_metric(y_pred=val_output_convert, y=val_labels_convert),dim=0))\n",
    "        \n",
    "        metric_batch_val = dice_metric_batch.aggregate()#dice avg\n",
    "        dice_metric_batch.reset()\n",
    "        mean_dice_val = dice_metric.aggregate().item()\n",
    "        dice_metric.reset()\n",
    "        mean_nsd=nsd_metric.aggregate().item() #NSD\n",
    "        nsd_metric.reset()\n",
    "\n",
    "    return mean_dice_val,metric_batch_val,mean_nsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4029d24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate (X / X Steps) (dice=X.X):   0%|                  | 0/6 [00:00<?, ?it/s]None of the inputs have requires_grad=True. Gradients will be None\n",
      "Validate (0 / 10 Steps): 100%|████████████████████| 6/6 [00:15<00:00,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dice_val:0.8889410495758057,dice_batch_val:tensor([0.9968, 0.9538, 0.9440, 0.8971, 0.9188, 0.8723, 0.7771, 0.7516],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#avg 5 fold\n",
    "model.load_state_dict(torch.load(os.path.join(\"/home/user/Documents/swin_unetr/swin_unetr_model\", \"swinunetr_fold1_best_metric_model.pth\")))\n",
    "# model.load_state_dict(torch.load(os.path.join(\"/home/user/Documents/swin_unetr/swin_unetr_model\", \"swinunetr_fold1_best_metric_model.pth\")))\n",
    "model.eval()\n",
    "case_num=1\n",
    "\n",
    "epoch_iterator_val = tqdm(val_loader, desc=\"Validate (X / X Steps) (dice=X.X)\", dynamic_ncols=True)\n",
    "dice_val,metric_batch_val = validation(epoch_iterator_val)\n",
    "print(\"dice_val:{},dice_batch_val:{}\".format(dice_val,metric_batch_val))\n",
    "# epoch_loss /= step\n",
    "# epoch_loss_values.append(epoch_loss)\n",
    "# metric_values.append(dice_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4827c0fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate (0 / 10 Steps): 100%|████████████████████| 6/6 [03:48<00:00, 38.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dice_val:0.8959500193595886,dice_batch_val:tensor([0.9969, 0.9580, 0.9559, 0.9220, 0.9271, 0.8701, 0.7714, 0.7662],\n",
      "       device='cuda:0'),mean_nsd:0.6873403548880359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#NSD\n",
    "model.load_state_dict(torch.load(os.path.join(\"/home/user/Documents/swin_unetr/swin_unetr_model\", \"swinunetr_fold1_best_metric_model.pth\")))\n",
    "# model.load_state_dict(torch.load(os.path.join(\"/home/user/Documents/swin_unetr/swin_unetr_model\", \"swinunetr_fold1_best_metric_model.pth\")))\n",
    "model.eval()\n",
    "case_num=1\n",
    "\n",
    "epoch_iterator_val = tqdm(val_loader, desc=\"Validate (X / X Steps) (dice=X.X)\", dynamic_ncols=True)\n",
    "dice_val,metric_batch_val,mean_nsd = validation(epoch_iterator_val)\n",
    "print(\"mean_nsd:{}\".format(dice_val,metric_batch_val,mean_nsd))\n",
    "# epoch_loss /= step\n",
    "# epoch_loss_values.append(epoch_loss)\n",
    "# metric_values.append(dice_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3529580",
   "metadata": {},
   "outputs": [],
   "source": [
    "#UNETR vit change to wavelet vit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d7a6132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in vit torch.Size([4, 1, 96, 96, 96])\n",
      "x_in affter embed torch.Size([4, 216, 384])\n",
      "torch.Size([4, 216, 384])\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "test = torch.randn(4, 1, 96, 96, 96).cuda()\n",
    "output = model(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba99753",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MMH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e42e90cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 1.1.0\n",
      "Numpy version: 1.21.6\n",
      "Pytorch version: 1.13.1+cu117\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
      "MONAI rev id: a2ec3752f54bfc3b40e7952234fbeb5452ed63e3\n",
      "MONAI __file__: /home/user/anaconda3/envs/kevin/lib/python3.7/site-packages/monai/__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "Nibabel version: 4.0.2\n",
      "scikit-image version: 0.19.3\n",
      "Pillow version: 9.4.0\n",
      "Tensorboard version: 2.11.2\n",
      "gdown version: 4.7.1\n",
      "TorchVision version: 0.14.1+cu117\n",
      "tqdm version: 4.65.0\n",
      "lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "psutil version: 5.9.0\n",
      "pandas version: 1.3.5\n",
      "einops version: 0.6.1\n",
      "transformers version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "mlflow version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "pynrrd version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#inference MMH\n",
    "#导入用到得module\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import itk\n",
    "from PIL import Image\n",
    "import tempfile\n",
    "from monai.data import ITKReader, PILReader\n",
    "from monai.transforms import (\n",
    "    LoadImage, LoadImaged, EnsureChannelFirstd,\n",
    "    Resized, EnsureTyped, Compose,Invertd,AsDiscreted, SaveImaged,\n",
    ")\n",
    "from monai.handlers.utils import from_engine\n",
    "\n",
    "from monai.config import print_config\n",
    "\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.data import NiftiSaver\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d04c0c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = UNETR(\n",
    "    in_channels=1,\n",
    "    out_channels=8,\n",
    "    img_size=(96, 96, 96),\n",
    "    feature_size=16,\n",
    "    hidden_size=384,\n",
    "    mlp_dim=3072,\n",
    "    num_heads=12,\n",
    "    pos_embed=\"perceptron\",\n",
    "    norm_name=\"instance\",\n",
    "    res_block=True,\n",
    "    dropout_rate=0.0,\n",
    ").to(device)\n",
    "\n",
    "loss_function = DiceCELoss(to_onehot_y=True, softmax=True)\n",
    "# loss_function = DiceLoss(to_onehot_y=True, softmax=True)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99891421",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(epoch_iterator_val):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in epoch_iterator_val:\n",
    "            val_inputs, val_labels = (batch[\"image\"].cuda(), batch[\"label\"].cuda())\n",
    "            with torch.cuda.amp.autocast():\n",
    "                val_outputs = sliding_window_inference(val_inputs, (96, 96, 96), 4, model)\n",
    "            val_labels_list = decollate_batch(val_labels)\n",
    "            val_labels_convert = [post_label(val_label_tensor) for val_label_tensor in val_labels_list]\n",
    "            val_outputs_list = decollate_batch(val_outputs)\n",
    "            val_output_convert = [post_pred(val_pred_tensor) for val_pred_tensor in val_outputs_list]\n",
    "            dice_metric(y_pred=val_output_convert, y=val_labels_convert)\n",
    "            epoch_iterator_val.set_description(\"Validate (%d / %d Steps)\" % (global_step, 10.0))\n",
    "        mean_dice_val = dice_metric.aggregate().item()\n",
    "        dice_metric.reset()\n",
    "    return mean_dice_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "24db1d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iterations = 25000#30000\n",
    "eval_num = 500\n",
    "post_label = AsDiscrete(to_onehot=8)\n",
    "post_pred = AsDiscrete(argmax=True, to_onehot=8)\n",
    "dice_metric = DiceMetric(include_background=True, reduction=\"mean\", get_not_nans=False)\n",
    "global_step = 0\n",
    "dice_val_best = 0.0\n",
    "global_step_best = 0\n",
    "epoch_loss_values = []\n",
    "metric_values = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3cca30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████████████████████| 57/57 [00:18<00:00,  3.12it/s]\n"
     ]
    }
   ],
   "source": [
    "data_dir='/home/user/Documents/unetr/research-contributions/UNETR/BTCV/dataset/MMH_0503/'\n",
    "split_json = \"dataset_inf.json\"\n",
    "datasets = data_dir + split_json\n",
    "\n",
    "val_transforms = Compose(\n",
    "   [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            pixdim=(1.5, 1.5, 2.0),\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"image\"],\n",
    "            a_min=-175,\n",
    "            a_max=250,\n",
    "            b_min=0.0,\n",
    "            b_max=1.0,\n",
    "            clip=True,\n",
    "        ),\n",
    "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "        RandCropByPosNegLabeld(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            label_key=\"label\",\n",
    "            spatial_size=(96, 96, 96),\n",
    "            pos=1,\n",
    "            neg=1,\n",
    "            num_samples=4,\n",
    "            image_key=\"image\",\n",
    "            image_threshold=0,\n",
    "        ),\n",
    "        RandFlipd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            spatial_axis=[0],\n",
    "            prob=0.10,\n",
    "        ),\n",
    "        RandFlipd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            spatial_axis=[1],\n",
    "            prob=0.10,\n",
    "        ),\n",
    "        RandFlipd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            spatial_axis=[2],\n",
    "            prob=0.10,\n",
    "        ),\n",
    "        RandRotate90d(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            prob=0.10,\n",
    "            max_k=3,\n",
    "        ),\n",
    "        RandShiftIntensityd(\n",
    "            keys=[\"image\"],\n",
    "            offsets=0.10,\n",
    "            prob=0.50,\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "val_files = load_decathlon_datalist(datasets, True, \"validation\")\n",
    "val_ds = CacheDataset(data=val_files, transform=val_transforms, cache_num=57, cache_rate=1.0, num_workers=4)\n",
    "val_loader = ThreadDataLoader(val_ds, num_workers=0, batch_size=1)\n",
    "\n",
    "# as explained in the \"Setup transforms\" section above, we want cached training images to not have metadata, and validations to have metadata\n",
    "# the EnsureTyped transforms allow us to make this distinction\n",
    "# on the other hand, set_track_meta is a global API; doing so here makes sure subsequent transforms (i.e., random transforms for training)\n",
    "# will be carried out as Tensors, not MetaTensors\n",
    "# set_track_meta(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5878252a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate (0 / 10 Steps): 100%|██████████████████| 57/57 [00:12<00:00,  4.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dice_val: 0.2666066586971283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#fold0\n",
    "model.load_state_dict(torch.load(os.path.join(\"/home/user/Documents/swin_unetr/dwt_swinunetr_model\", \"waveunetr_concatViT_fold0_best_metric_model.pth\")))\n",
    "# model.load_state_dict(torch.load(os.path.join(\"/home/user/Documents/swin_unetr/swin_unetr_model\", \"swinunetr_fold1_best_metric_model.pth\")))\n",
    "model.eval()\n",
    "case_num=1\n",
    "\n",
    "epoch_iterator_val = tqdm(val_loader, desc=\"Validate (X / X Steps) (dice=X.X)\", dynamic_ncols=True)\n",
    "dice_val = validation(epoch_iterator_val)\n",
    "print(\"dice_val:\",dice_val)\n",
    "# epoch_loss /= step\n",
    "# epoch_loss_values.append(epoch_loss)\n",
    "# metric_values.append(dice_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6894c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate (0 / 10 Steps): 100%|██████████████████| 57/57 [00:11<00:00,  5.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dice_val: 0.34900960326194763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#fold1\n",
    "model.load_state_dict(torch.load(os.path.join(\"/home/user/Documents/swin_unetr/dwt_swinunetr_model\", \"waveunetr_concatViT_fold1_best_metric_model.pth\")))\n",
    "# model.load_state_dict(torch.load(os.path.join(\"/home/user/Documents/swin_unetr/swin_unetr_model\", \"swinunetr_fold1_best_metric_model.pth\")))\n",
    "model.eval()\n",
    "case_num=1\n",
    "\n",
    "epoch_iterator_val = tqdm(val_loader, desc=\"Validate (X / X Steps) (dice=X.X)\", dynamic_ncols=True)\n",
    "dice_val = validation(epoch_iterator_val)\n",
    "print(\"dice_val:\",dice_val)\n",
    "# epoch_loss /= step\n",
    "# epoch_loss_values.append(epoch_loss)\n",
    "# metric_values.append(dice_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "248032d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate (0 / 10 Steps): 100%|██████████████████| 57/57 [00:11<00:00,  5.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dice_val: 0.31487661600112915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#fold2\n",
    "model.load_state_dict(torch.load(os.path.join(\"/home/user/Documents/swin_unetr/dwt_swinunetr_model\", \"waveunetr_concatViT_fold2_best_metric_model.pth\")))\n",
    "# model.load_state_dict(torch.load(os.path.join(\"/home/user/Documents/swin_unetr/swin_unetr_model\", \"swinunetr_fold1_best_metric_model.pth\")))\n",
    "model.eval()\n",
    "case_num=1\n",
    "\n",
    "epoch_iterator_val = tqdm(val_loader, desc=\"Validate (X / X Steps) (dice=X.X)\", dynamic_ncols=True)\n",
    "dice_val = validation(epoch_iterator_val)\n",
    "print(\"dice_val:\",dice_val)\n",
    "# epoch_loss /= step\n",
    "# epoch_loss_values.append(epoch_loss)\n",
    "# metric_values.append(dice_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b57d6f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate (0 / 10 Steps): 100%|██████████████████| 57/57 [00:11<00:00,  5.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dice_val: 0.4232094883918762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#fold3\n",
    "model.load_state_dict(torch.load(os.path.join(\"/home/user/Documents/swin_unetr/dwt_swinunetr_model\", \"waveunetr_concatViT_fold3_best_metric_model.pth\")))\n",
    "# model.load_state_dict(torch.load(os.path.join(\"/home/user/Documents/swin_unetr/swin_unetr_model\", \"swinunetr_fold1_best_metric_model.pth\")))\n",
    "model.eval()\n",
    "case_num=1\n",
    "\n",
    "epoch_iterator_val = tqdm(val_loader, desc=\"Validate (X / X Steps) (dice=X.X)\", dynamic_ncols=True)\n",
    "dice_val = validation(epoch_iterator_val)\n",
    "print(\"dice_val:\",dice_val)\n",
    "# epoch_loss /= step\n",
    "# epoch_loss_values.append(epoch_loss)\n",
    "# metric_values.append(dice_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c38b5aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate (0 / 10 Steps): 100%|██████████████████| 57/57 [00:11<00:00,  4.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dice_val: 0.3234732747077942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#fold4\n",
    "model.load_state_dict(torch.load(os.path.join(\"/home/user/Documents/swin_unetr/dwt_swinunetr_model\", \"waveunetr_concatViT_fold4_best_metric_model.pth\")))\n",
    "# model.load_state_dict(torch.load(os.path.join(\"/home/user/Documents/swin_unetr/swin_unetr_model\", \"swinunetr_fold1_best_metric_model.pth\")))\n",
    "model.eval()\n",
    "case_num=1\n",
    "\n",
    "epoch_iterator_val = tqdm(val_loader, desc=\"Validate (X / X Steps) (dice=X.X)\", dynamic_ncols=True)\n",
    "dice_val = validation(epoch_iterator_val)\n",
    "print(\"dice_val:\",dice_val)\n",
    "# epoch_loss /= step\n",
    "# epoch_loss_values.append(epoch_loss)\n",
    "# metric_values.append(dice_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7937673f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inference MMH up down flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c09d70af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████████████████████| 57/57 [00:19<00:00,  2.93it/s]\n"
     ]
    }
   ],
   "source": [
    "data_dir='/home/user/Documents/unetr/research-contributions/UNETR/BTCV/dataset/MMH_0503_updown_flip/'\n",
    "split_json = \"dataset_inf.json\"\n",
    "datasets = data_dir + split_json\n",
    "\n",
    "val_transforms = Compose(\n",
    "   [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            pixdim=(1.5, 1.5, 2.0),\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"image\"],\n",
    "            a_min=-175,\n",
    "            a_max=250,\n",
    "            b_min=0.0,\n",
    "            b_max=1.0,\n",
    "            clip=True,\n",
    "        ),\n",
    "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "        RandCropByPosNegLabeld(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            label_key=\"label\",\n",
    "            spatial_size=(96, 96, 96),\n",
    "            pos=1,\n",
    "            neg=1,\n",
    "            num_samples=4,\n",
    "            image_key=\"image\",\n",
    "            image_threshold=0,\n",
    "        ),\n",
    "        RandFlipd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            spatial_axis=[0],\n",
    "            prob=0.10,\n",
    "        ),\n",
    "        RandFlipd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            spatial_axis=[1],\n",
    "            prob=0.10,\n",
    "        ),\n",
    "        RandFlipd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            spatial_axis=[2],\n",
    "            prob=0.10,\n",
    "        ),\n",
    "        RandRotate90d(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            prob=0.10,\n",
    "            max_k=3,\n",
    "        ),\n",
    "        RandShiftIntensityd(\n",
    "            keys=[\"image\"],\n",
    "            offsets=0.10,\n",
    "            prob=0.50,\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_files = load_decathlon_datalist(datasets, True, \"validation\")\n",
    "val_ds = CacheDataset(data=val_files, transform=val_transforms, cache_num=100, cache_rate=1.0, num_workers=4)\n",
    "val_loader = ThreadDataLoader(val_ds, num_workers=0, batch_size=1)\n",
    "\n",
    "# as explained in the \"Setup transforms\" section above, we want cached training images to not have metadata, and validations to have metadata\n",
    "# the EnsureTyped transforms allow us to make this distinction\n",
    "# on the other hand, set_track_meta is a global API; doing so here makes sure subsequent transforms (i.e., random transforms for training)\n",
    "# will be carried out as Tensors, not MetaTensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61efef9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate (0 / 10 Steps): 100%|██████████████████| 57/57 [00:11<00:00,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dice_val: 0.2643609642982483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#fold0\n",
    "model.load_state_dict(torch.load(os.path.join(\"/home/user/Documents/swin_unetr/dwt_swinunetr_model\", \"waveunetr_concatViT_fold0_best_metric_model.pth\")))\n",
    "# model.load_state_dict(torch.load(os.path.join(\"/home/user/Documents/swin_unetr/swin_unetr_model\", \"swinunetr_fold1_best_metric_model.pth\")))\n",
    "model.eval()\n",
    "case_num=1\n",
    "\n",
    "epoch_iterator_val = tqdm(val_loader, desc=\"Validate (X / X Steps) (dice=X.X)\", dynamic_ncols=True)\n",
    "dice_val = validation(epoch_iterator_val)\n",
    "print(\"dice_val:\",dice_val)\n",
    "# epoch_loss /= step\n",
    "# epoch_loss_values.append(epoch_loss)\n",
    "# metric_values.append(dice_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f6ac4fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate (0 / 10 Steps): 100%|██████████████████| 57/57 [00:11<00:00,  5.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dice_val: 0.30316197872161865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#fold1\n",
    "model.load_state_dict(torch.load(os.path.join(\"/home/user/Documents/swin_unetr/dwt_swinunetr_model\", \"waveunetr_concatViT_fold1_best_metric_model.pth\")))\n",
    "# model.load_state_dict(torch.load(os.path.join(\"/home/user/Documents/swin_unetr/swin_unetr_model\", \"swinunetr_fold1_best_metric_model.pth\")))\n",
    "model.eval()\n",
    "case_num=1\n",
    "\n",
    "epoch_iterator_val = tqdm(val_loader, desc=\"Validate (X / X Steps) (dice=X.X)\", dynamic_ncols=True)\n",
    "dice_val = validation(epoch_iterator_val)\n",
    "print(\"dice_val:\",dice_val)\n",
    "# epoch_loss /= step\n",
    "# epoch_loss_values.append(epoch_loss)\n",
    "# metric_values.append(dice_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fb83c9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate (0 / 10 Steps): 100%|██████████████████| 57/57 [00:11<00:00,  5.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dice_val: 0.32531973719596863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#fold2\n",
    "model.load_state_dict(torch.load(os.path.join(\"/home/user/Documents/swin_unetr/dwt_swinunetr_model\", \"waveunetr_concatViT_fold2_best_metric_model.pth\")))\n",
    "# model.load_state_dict(torch.load(os.path.join(\"/home/user/Documents/swin_unetr/swin_unetr_model\", \"swinunetr_fold1_best_metric_model.pth\")))\n",
    "model.eval()\n",
    "case_num=1\n",
    "\n",
    "epoch_iterator_val = tqdm(val_loader, desc=\"Validate (X / X Steps) (dice=X.X)\", dynamic_ncols=True)\n",
    "dice_val = validation(epoch_iterator_val)\n",
    "print(\"dice_val:\",dice_val)\n",
    "# epoch_loss /= step\n",
    "# epoch_loss_values.append(epoch_loss)\n",
    "# metric_values.append(dice_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "07611fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate (0 / 10 Steps): 100%|██████████████████| 57/57 [00:11<00:00,  5.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dice_val: 0.3863683342933655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#fold3\n",
    "model.load_state_dict(torch.load(os.path.join(\"/home/user/Documents/swin_unetr/dwt_swinunetr_model\", \"waveunetr_concatViT_fold3_best_metric_model.pth\")))\n",
    "# model.load_state_dict(torch.load(os.path.join(\"/home/user/Documents/swin_unetr/swin_unetr_model\", \"swinunetr_fold1_best_metric_model.pth\")))\n",
    "model.eval()\n",
    "case_num=1\n",
    "\n",
    "epoch_iterator_val = tqdm(val_loader, desc=\"Validate (X / X Steps) (dice=X.X)\", dynamic_ncols=True)\n",
    "dice_val = validation(epoch_iterator_val)\n",
    "print(\"dice_val:\",dice_val)\n",
    "# epoch_loss /= step\n",
    "# epoch_loss_values.append(epoch_loss)\n",
    "# metric_values.append(dice_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "16a3e5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate (0 / 10 Steps): 100%|██████████████████| 57/57 [00:11<00:00,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dice_val: 0.3078237771987915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#fold4\n",
    "model.load_state_dict(torch.load(os.path.join(\"/home/user/Documents/swin_unetr/dwt_swinunetr_model\", \"waveunetr_concatViT_fold4_best_metric_model.pth\")))\n",
    "# model.load_state_dict(torch.load(os.path.join(\"/home/user/Documents/swin_unetr/swin_unetr_model\", \"swinunetr_fold1_best_metric_model.pth\")))\n",
    "model.eval()\n",
    "case_num=1\n",
    "\n",
    "epoch_iterator_val = tqdm(val_loader, desc=\"Validate (X / X Steps) (dice=X.X)\", dynamic_ncols=True)\n",
    "dice_val = validation(epoch_iterator_val)\n",
    "print(\"dice_val:\",dice_val)\n",
    "# epoch_loss /= step\n",
    "# epoch_loss_values.append(epoch_loss)\n",
    "# metric_values.append(dice_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f204bdeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
