{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b2210a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q \"monai-weekly[nibabel, tqdm, einops]\"\n",
    "!python -c \"import matplotlib\" || pip install -q matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b1b971b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 1.1.0\n",
      "Numpy version: 1.21.6\n",
      "Pytorch version: 1.13.1+cu117\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
      "MONAI rev id: a2ec3752f54bfc3b40e7952234fbeb5452ed63e3\n",
      "MONAI __file__: /home/user/anaconda3/envs/kevin/lib/python3.7/site-packages/monai/__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "Nibabel version: 4.0.2\n",
      "scikit-image version: 0.19.3\n",
      "Pillow version: 9.4.0\n",
      "Tensorboard version: 2.11.2\n",
      "gdown version: 4.7.1\n",
      "TorchVision version: 0.14.1+cu117\n",
      "tqdm version: 4.65.0\n",
      "lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "psutil version: 5.9.0\n",
      "pandas version: 1.3.5\n",
      "einops version: 0.6.1\n",
      "transformers version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "mlflow version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "pynrrd version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from monai.losses import DiceCELoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    EnsureChannelFirstd,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandFlipd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    RandShiftIntensityd,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    RandRotate90d,\n",
    ")\n",
    "\n",
    "from monai.config import print_config\n",
    "from monai.metrics import DiceMetric,SurfaceDiceMetric,compute_surface_dice\n",
    "from monai.losses import DiceLoss\n",
    "from monai.networks.nets import UNETR,UNet,BasicUNet\n",
    "from monai.networks.layers import Norm\n",
    "from monai.networks.nets import SwinUNETR\n",
    "\n",
    "from monai.data import (\n",
    "    ThreadDataLoader,\n",
    "    DataLoader,\n",
    "    CacheDataset,\n",
    "    load_decathlon_datalist,\n",
    "    decollate_batch,\n",
    ")\n",
    "\n",
    "import logging\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "import torch\n",
    "\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f422275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 1.1.0\n",
      "Numpy version: 1.21.6\n",
      "Pytorch version: 1.13.1+cu117\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
      "MONAI rev id: a2ec3752f54bfc3b40e7952234fbeb5452ed63e3\n",
      "MONAI __file__: /home/user/anaconda3/envs/kevin/lib/python3.7/site-packages/monai/__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "Nibabel version: 4.0.2\n",
      "scikit-image version: 0.19.3\n",
      "Pillow version: 9.4.0\n",
      "Tensorboard version: 2.11.2\n",
      "gdown version: 4.7.1\n",
      "TorchVision version: 0.14.1+cu117\n",
      "tqdm version: 4.65.0\n",
      "lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "psutil version: 5.9.0\n",
      "pandas version: 1.3.5\n",
      "einops version: 0.6.1\n",
      "transformers version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "mlflow version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "pynrrd version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from monai.losses import DiceCELoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    EnsureChannelFirstd,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandFlipd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    RandShiftIntensityd,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    RandRotate90d,\n",
    ")\n",
    "\n",
    "from monai.config import print_config\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.networks.nets import UNETR\n",
    "\n",
    "from monai.data import (\n",
    "    DataLoader,\n",
    "    CacheDataset,\n",
    "    load_decathlon_datalist,\n",
    "    decollate_batch,\n",
    ")\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00497c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/tmp2rietd32\n"
     ]
    }
   ],
   "source": [
    "directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
    "root_dir = tempfile.mkdtemp() if directory is None else directory\n",
    "print(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d0e7a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            pixdim=(1.5, 1.5, 2.0),\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"image\"],\n",
    "            a_min=-175,\n",
    "            a_max=250,\n",
    "            b_min=0.0,\n",
    "            b_max=1.0,\n",
    "            clip=True,\n",
    "        ),\n",
    "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "        RandCropByPosNegLabeld(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            label_key=\"label\",\n",
    "            spatial_size=(96, 96, 96),\n",
    "            pos=1,\n",
    "            neg=1,\n",
    "            num_samples=4,\n",
    "            image_key=\"image\",\n",
    "            image_threshold=0,\n",
    "        ),\n",
    "        RandFlipd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            spatial_axis=[0],\n",
    "            prob=0.10,\n",
    "        ),\n",
    "        RandFlipd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            spatial_axis=[1],\n",
    "            prob=0.10,\n",
    "        ),\n",
    "        RandFlipd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            spatial_axis=[2],\n",
    "            prob=0.10,\n",
    "        ),\n",
    "        RandRotate90d(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            prob=0.10,\n",
    "            max_k=3,\n",
    "        ),\n",
    "        RandShiftIntensityd(\n",
    "            keys=[\"image\"],\n",
    "            offsets=0.10,\n",
    "            prob=0.50,\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            pixdim=(1.5, 1.5, 2.0),\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        ScaleIntensityRanged(keys=[\"image\"], a_min=-175, a_max=250, b_min=0.0, b_max=1.0, clip=True),\n",
    "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "        RandCropByPosNegLabeld(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            label_key=\"label\",\n",
    "            spatial_size=(96, 96, 96),\n",
    "            pos=1,\n",
    "            neg=1,\n",
    "            num_samples=4,\n",
    "            image_key=\"image\",\n",
    "            image_threshold=0,\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "#训练python脚本中import torch后，加上下面这句。 \n",
    "torch.multiprocessing.set_sharing_strategy('file_system')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad5900c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#WORD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ee66130",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████████████████████| 80/80 [02:05<00:00,  1.56s/it]\n",
      "Loading dataset: 100%|██████████████████████████| 20/20 [00:35<00:00,  1.78s/it]\n"
     ]
    }
   ],
   "source": [
    "#pretrain on word\n",
    "data_dir = \"/home/user/Documents/unetr/research-contributions/UNETR/BTCV/dataset/dataset1/\"\n",
    "split_json = \"dataset_0.json\"\n",
    "\n",
    "datasets = data_dir + split_json\n",
    "datalist = load_decathlon_datalist(datasets, True, \"training\")\n",
    "val_files = load_decathlon_datalist(datasets, True, \"validation\")\n",
    "train_ds = CacheDataset(\n",
    "    data=datalist,\n",
    "    transform=train_transforms,\n",
    "    cache_num=80,#24\n",
    "    cache_rate=1.0,\n",
    "    num_workers=4,\n",
    ")\n",
    "train_loader = DataLoader(train_ds, batch_size=1, shuffle=True, num_workers=20, pin_memory=False)\n",
    "val_ds = CacheDataset(data=val_files, transform=val_transforms, cache_num=20, cache_rate=1.0, num_workers=4)#cache_num=6\n",
    "val_loader = DataLoader(val_ds, batch_size=1, shuffle=False, num_workers=4, pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4755cfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = UNETR(\n",
    "    in_channels=1,\n",
    "    out_channels=8,\n",
    "    img_size=(96, 96, 96),\n",
    "    feature_size=48,\n",
    "    hidden_size=768,\n",
    "    mlp_dim=3072,\n",
    "    num_heads=12,\n",
    "    pos_embed=\"perceptron\",\n",
    "    norm_name=\"instance\",\n",
    "    res_block=True,\n",
    "    dropout_rate=0.0,\n",
    ").to(device)\n",
    "\n",
    "loss_function = DiceCELoss(to_onehot_y=True, softmax=True)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a4314c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MICCAI 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba1bc4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████████████████████| 24/24 [00:21<00:00,  1.13it/s]\n",
      "Loading dataset: 100%|████████████████████████████| 6/6 [00:07<00:00,  1.17s/it]\n"
     ]
    }
   ],
   "source": [
    "#5 fold avg\n",
    "data_dir = \"/home/user/Documents/unetr/research-contributions/UNETR/BTCV/dataset/dataset0/\"\n",
    "split_json = \"dataset_0.json\"\n",
    "\n",
    "datasets = data_dir + split_json\n",
    "datalist = load_decathlon_datalist(datasets, True, \"training\")\n",
    "val_files = load_decathlon_datalist(datasets, True, \"validation\")\n",
    "train_ds = CacheDataset(\n",
    "    data=datalist,\n",
    "    transform=train_transforms,\n",
    "    cache_num=24,#24\n",
    "    cache_rate=1.0,\n",
    "    num_workers=4,\n",
    ")\n",
    "train_loader = DataLoader(train_ds, batch_size=1, shuffle=True, num_workers=8, pin_memory=False)\n",
    "val_ds = CacheDataset(data=val_files, transform=val_transforms, cache_num=6, cache_rate=1.0, num_workers=4)#cache_num=6\n",
    "val_loader = DataLoader(val_ds, batch_size=1, shuffle=False, num_workers=4, pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b87744b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = UNETR(\n",
    "    in_channels=1,\n",
    "    out_channels=8,\n",
    "    img_size=(96, 96, 96),\n",
    "    feature_size=16,\n",
    "    hidden_size=384,\n",
    "    mlp_dim=3072,\n",
    "    num_heads=12,\n",
    "    pos_embed=\"perceptron\",\n",
    "    norm_name=\"instance\",\n",
    "    res_block=True,\n",
    "    dropout_rate=0.0,\n",
    ").to(device)\n",
    "\n",
    "loss_function = DiceCELoss(to_onehot_y=True, softmax=True)\n",
    "# loss_function = DiceLoss(to_onehot_y=True, softmax=True)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db3eb982",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iterations = 25000\n",
    "eval_num = 500#500\n",
    "post_label = AsDiscrete(to_onehot=8)\n",
    "post_pred = AsDiscrete(argmax=True, to_onehot=8)\n",
    "\n",
    "dice_metric = DiceMetric(include_background=True, reduction=\"mean\", get_not_nans=False)\n",
    "dice_metric_batch=DiceMetric(include_background=True, reduction=\"mean_batch\", get_not_nans=False)\n",
    "# thresh=np.full((295,),1.0)\n",
    "nsd_metric=SurfaceDiceMetric(class_thresholds=[1.0,1.0,1.0,1.0,1.0,1.0,1.0],include_background=False,reduction=\"mean\")\n",
    "global_step = 0\n",
    "dice_val_best = 0.0\n",
    "global_step_best = 0\n",
    "epoch_loss_values = []\n",
    "metric_values = []\n",
    "import torch, gc\n",
    "def validation(epoch_iterator_val):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in epoch_iterator_val:\n",
    "            val_inputs, val_labels = (batch[\"image\"].cuda()\n",
    "                                      , batch[\"label\"].cuda())\n",
    "            val_outputs = sliding_window_inference(val_inputs, (96, 96, 96), 4, model,overlap=0.8)\n",
    "            val_labels_list = decollate_batch(val_labels)\n",
    "            val_labels_convert = [post_label(val_label_tensor) for val_label_tensor in val_labels_list]\n",
    "            val_outputs_list = decollate_batch(val_outputs)\n",
    "            val_output_convert = [post_pred(val_pred_tensor) for val_pred_tensor in val_outputs_list]\n",
    "                  \n",
    "            dice_metric(y_pred=val_output_convert, y=val_labels_convert)\n",
    "            dice_metric_batch(y_pred=val_output_convert, y=val_labels_convert)\n",
    "            \n",
    "            #NSD\n",
    "            nsd_metric(y_pred=val_output_convert[0].permute([1,0,2,3]),y=val_labels_convert[0].permute([1,0,2,3]))\n",
    "            \n",
    "            epoch_iterator_val.set_description(\"Validate (%d / %d Steps)\" % (global_step, 10.0))\n",
    "            \n",
    "            #each case dice\n",
    "#             for val_output_dice in val_output_convert:\n",
    "#                 print(\"each case dice\",torch.nanmean(dice_metric(y_pred=val_output_convert, y=val_labels_convert),dim=0))\n",
    "        \n",
    "        metric_batch_val = dice_metric_batch.aggregate()#dice avg\n",
    "        dice_metric_batch.reset()\n",
    "        mean_dice_val = dice_metric.aggregate().item()\n",
    "        dice_metric.reset()\n",
    "        mean_nsd=nsd_metric.aggregate().item() #NSD\n",
    "        nsd_metric.reset()\n",
    "\n",
    "    return mean_dice_val,metric_batch_val,mean_nsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a82b535e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate (0 / 10 Steps): 100%|████████████████████| 6/6 [00:01<00:00,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dice_val:0.8129405379295349,avg_dice_batch_val:tensor([0.9867, 0.9793, 0.9452, 0.8905, 0.9217, 0.8873, 0.7661, 0.7757,],device= 'cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#avg 5 fold\n",
    "model.load_state_dict(torch.load(os.path.join(\"/home/user/Documents/swin_unetr/dwt_swinunetr_model\", \"frequency_unetr_fold4_best_metric_model.pth\")))\n",
    "\n",
    "model.eval()\n",
    "case_num=1\n",
    "\n",
    "epoch_iterator_val = tqdm(val_loader, desc=\"Validate (X / X Steps) (dice=X.X)\", dynamic_ncols=True)\n",
    "dice_val,metric_batch_val = validation(epoch_iterator_val)\n",
    "print(\"dice_val:{},dice_batch_val:{}\".format(dice_val,metric_batch_val))\n",
    "# epoch_loss /= step\n",
    "# epoch_loss_values.append(epoch_loss)\n",
    "# metric_values.append(dice_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1b1afe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate (0 / 10 Steps): 100%|████████████████████| 6/6 [00:02<00:00,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_nsd:0.6980800530945819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#NSD\n",
    "model.load_state_dict(torch.load(os.path.join(\"/home/user/Documents/swin_unetr/dwt_swinunetr_model\", \"frequency_unetr_fold4_best_metric_model.pth\")))\n",
    "model.eval()\n",
    "case_num=1\n",
    "epoch_iterator_val = tqdm(val_loader, desc=\"Validate (X / X Steps) (dice=X.X)\", dynamic_ncols=True)\n",
    "dice_val,metric_batch_val,mean_nsd = validation(epoch_iterator_val)\n",
    "print(\"mean_nsd:{}\".format(mean_nsd))\n",
    "\n",
    "# epoch_loss /= step\n",
    "# epoch_loss_values.append(epoch_loss)\n",
    "# metric_values.append(dice_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa06e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#UNETR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d79b4016",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            pixdim=(1.5, 1.5, 2.0),\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"image\"],\n",
    "            a_min=-175,\n",
    "            a_max=250,\n",
    "            b_min=0.0,\n",
    "            b_max=1.0,\n",
    "            clip=True,\n",
    "        ),\n",
    "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "        RandCropByPosNegLabeld(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            label_key=\"label\",\n",
    "            spatial_size=(96, 96, 96),\n",
    "            pos=1,\n",
    "            neg=1,\n",
    "            num_samples=4,\n",
    "            image_key=\"image\",\n",
    "            image_threshold=0,\n",
    "        ),\n",
    "        RandFlipd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            spatial_axis=[0],\n",
    "            prob=0.10,\n",
    "        ),\n",
    "        RandFlipd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            spatial_axis=[1],\n",
    "            prob=0.10,\n",
    "        ),\n",
    "        RandFlipd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            spatial_axis=[2],\n",
    "            prob=0.10,\n",
    "        ),\n",
    "        RandRotate90d(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            prob=0.10,\n",
    "            max_k=3,\n",
    "        ),\n",
    "        RandShiftIntensityd(\n",
    "            keys=[\"image\"],\n",
    "            offsets=0.10,\n",
    "            prob=0.50,\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            pixdim=(1.5, 1.5, 2.0),\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        ScaleIntensityRanged(keys=[\"image\"], a_min=-175, a_max=250, b_min=0.0, b_max=1.0, clip=True),\n",
    "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59ed17b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = UNETR(\n",
    "    in_channels=1,\n",
    "    out_channels=8,#14\n",
    "    img_size=(96, 96, 96),\n",
    "    feature_size=16,#16 48\n",
    "    hidden_size=768,\n",
    "    mlp_dim=3072,\n",
    "    num_heads=12,\n",
    "    pos_embed=\"perceptron\",\n",
    "    norm_name=\"instance\",\n",
    "    res_block=True,\n",
    "    dropout_rate=0.0,\n",
    ").to(device)\n",
    "\n",
    "loss_function = DiceCELoss(to_onehot_y=True, softmax=True)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fca626e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate (0 / 10 Steps): 100%|████████████████████| 6/6 [00:53<00:00,  8.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dice_val:0.85323166847229,dice_batch_val:tensor([0.9961, 0.9536, 0.9415, 0.9012, 0.8969, 0.8279, 0.6192, 0.6894],\n",
      "       device='cuda:0'),mean_nsd:0.6207441291680157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#NSD\n",
    "model.load_state_dict(torch.load(os.path.join(\"/home/user/Documents/unetr\", \"unetr_fold1_best_metric_model.pth\")))\n",
    "model.eval()\n",
    "case_num=1\n",
    "epoch_iterator_val = tqdm(val_loader, desc=\"Validate (X / X Steps) (dice=X.X)\", dynamic_ncols=True)\n",
    "dice_val,metric_batch_val,mean_nsd = validation(epoch_iterator_val)\n",
    "print(\"dice_val:{},dice_batch_val:{},mean_nsd:{}\".format(dice_val,metric_batch_val,mean_nsd))\n",
    "\n",
    "# epoch_loss /= step\n",
    "# epoch_loss_values.append(epoch_loss)\n",
    "# metric_values.append(dice_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5463cd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82283e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicUNet features: (32, 32, 64, 128, 256, 32).\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = UNet(\n",
    "#     spatial_dims=3,\n",
    "#     in_channels=1,\n",
    "#     out_channels=2,\n",
    "#     channels=(16, 32, 64, 128, 256),\n",
    "#     strides=(2, 2, 2, 2),\n",
    "#     num_res_units=2,\n",
    "#     norm=Norm.BATCH,\n",
    "# ).to(device)\n",
    "model = BasicUNet(spatial_dims=3,\n",
    "                  in_channels=1,\n",
    "                  out_channels=8,\n",
    "                  features=(32, 32, 64, 128, 256, 32),\n",
    "                  norm=Norm.BATCH).to(device)\n",
    "\n",
    "loss_function = DiceLoss(to_onehot_y=True, softmax=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-4)\n",
    "# torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f920458",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate (0 / 10 Steps): 100%|████████████████████| 6/6 [01:10<00:00, 11.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dice_val:0.8381698131561279,dice_batch_val:tensor([0.9945, 0.9241, 0.9456, 0.8212, 0.8333, 0.8044, 0.7027, 0.6795],\n",
      "       device='cuda:0'),mean_nsd:0.4965438600720117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#NSD\n",
    "model.load_state_dict(torch.load(os.path.join(\"/media/user/2tb/model/unet_model\", \"unetfold1_best_metric_model.pth\")))\n",
    "model.eval()\n",
    "case_num=1\n",
    "epoch_iterator_val = tqdm(val_loader, desc=\"Validate (X / X Steps) (dice=X.X)\", dynamic_ncols=True)\n",
    "dice_val,metric_batch_val,mean_nsd = validation(epoch_iterator_val)\n",
    "print(\"dice_val:{},dice_batch_val:{},mean_nsd:{}\".format(dice_val,metric_batch_val,mean_nsd))\n",
    "\n",
    "# epoch_loss /= step\n",
    "# epoch_loss_values.append(epoch_loss)\n",
    "# metric_values.append(dice_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3529580",
   "metadata": {},
   "outputs": [],
   "source": [
    "#UNETR vit change to wavelet vit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d7a6132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_in vit torch.Size([4, 1, 96, 96, 96])\n",
      "x_in affter embed torch.Size([4, 216, 384])\n",
      "torch.Size([4, 216, 384])\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "test = torch.randn(4, 1, 96, 96, 96).cuda()\n",
    "output = model(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84cd3a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 1.1.0\n",
      "Numpy version: 1.21.6\n",
      "Pytorch version: 1.13.1+cu117\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
      "MONAI rev id: a2ec3752f54bfc3b40e7952234fbeb5452ed63e3\n",
      "MONAI __file__: /home/user/anaconda3/envs/kevin/lib/python3.7/site-packages/monai/__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "Nibabel version: 4.0.2\n",
      "scikit-image version: 0.19.3\n",
      "Pillow version: 9.4.0\n",
      "Tensorboard version: 2.11.2\n",
      "gdown version: 4.7.1\n",
      "TorchVision version: 0.14.1+cu117\n",
      "tqdm version: 4.65.0\n",
      "lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "psutil version: 5.9.0\n",
      "pandas version: 1.3.5\n",
      "einops version: 0.6.1\n",
      "transformers version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "mlflow version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "pynrrd version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#UNETR inference MMH\n",
    "#导入用到得module\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import itk\n",
    "from PIL import Image\n",
    "import tempfile\n",
    "from monai.data import ITKReader, PILReader\n",
    "from monai.transforms import (\n",
    "    LoadImage, LoadImaged, EnsureChannelFirstd,\n",
    "    Resized, EnsureTyped, Compose,Invertd,AsDiscreted, SaveImaged,\n",
    ")\n",
    "from monai.handlers.utils import from_engine\n",
    "\n",
    "from monai.config import print_config\n",
    "\n",
    "print_config()\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.data import NiftiSaver\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "from monai.data import ThreadDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d312556",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|████████████████████████████| 6/6 [00:03<00:00,  1.86it/s]\n"
     ]
    }
   ],
   "source": [
    "# data_dir='/home/user/Documents/unetr/research-contributions/UNETR/BTCV/dataset/MMH_0503/'\n",
    "# split_json = \"dataset_inf.json\"\n",
    "data_dir = \"/home/user/Documents/unetr/research-contributions/UNETR/BTCV/dataset/dataset0/\"\n",
    "split_json = \"dataset_4.json\"\n",
    "datasets = data_dir + split_json\n",
    "\n",
    "test_files = load_decathlon_datalist(datasets, True, \"validation\")\n",
    "\n",
    "test_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\"]),\n",
    "        Orientationd(keys=[\"image\"], axcodes=\"RAS\"),\n",
    "        Spacingd(\n",
    "            keys=[\"image\"],\n",
    "            pixdim=(1.5, 1.5, 2.0),\n",
    "            mode=(\"bilinear\"),\n",
    "        ),\n",
    "        ScaleIntensityRanged(keys=[\"image\"], a_min=-175, a_max=250, b_min=0.0, b_max=1.0, clip=True),\n",
    "        CropForegroundd(keys=[\"image\"], source_key=\"image\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "post_transforms = Compose(\n",
    "    [\n",
    "        Invertd(\n",
    "            keys=\"pred\",\n",
    "            transform=test_transforms,\n",
    "            orig_keys=\"image\",\n",
    "            meta_keys=\"pred_meta_dict\",\n",
    "            orig_meta_keys=\"image_meta_dict\",\n",
    "            meta_key_postfix=\"meta_dict\",\n",
    "            nearest_interp=False,\n",
    "            to_tensor=True,\n",
    "        ),\n",
    "        AsDiscreted(keys=\"pred\", argmax=True),\n",
    "        SaveImaged(keys=\"pred\", meta_keys=\"pred_meta_dict\", output_dir=\"/home/user/Documents/unetr/research-contributions/UNETR/BTCV/dataset/dataset0/unet_output\", output_postfix=\"\", resample=False),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# test_ds = CacheDataset(data=test_files, transform=test_transforms, cache_num=114, cache_rate=1.0, num_workers=4)\n",
    "test_ds = CacheDataset(data=test_files, transform=test_transforms, num_workers=4)\n",
    "test_loader = ThreadDataLoader(test_ds, num_workers=0, batch_size=1)\n",
    "\n",
    "# data = transform(img_path).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6f8b57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicUNet features: (32, 32, 64, 128, 256, 32).\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = UNet(\n",
    "#     spatial_dims=3,\n",
    "#     in_channels=1,\n",
    "#     out_channels=2,\n",
    "#     channels=(16, 32, 64, 128, 256),\n",
    "#     strides=(2, 2, 2, 2),\n",
    "#     num_res_units=2,\n",
    "#     norm=Norm.BATCH,\n",
    "# ).to(device)\n",
    "model = BasicUNet(spatial_dims=3,\n",
    "                  in_channels=1,\n",
    "                  out_channels=8,\n",
    "                  features=(32, 32, 64, 128, 256, 32),\n",
    "                  norm=Norm.BATCH).to(device)\n",
    "\n",
    "loss_function = DiceLoss(to_onehot_y=True, softmax=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-4)\n",
    "# torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9823c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #swinunetr\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# model = SwinUNETR(\n",
    "#     img_size=(96, 96, 96),\n",
    "#     in_channels=1,\n",
    "#     out_channels=8,\n",
    "#     feature_size=48,\n",
    "#     use_checkpoint=True,\n",
    "# ).to(device)\n",
    "# torch.backends.cudnn.benchmark = True\n",
    "# loss_function = DiceCELoss(to_onehot_y=True, softmax=True)\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "# scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a1a6a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#UNETR frequency-UNETR\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# model = UNETR(\n",
    "#     in_channels=1,\n",
    "#     out_channels=8,#14\n",
    "#     img_size=(96, 96, 96),\n",
    "#     feature_size=16,#16 48\n",
    "#     hidden_size=768,\n",
    "#     mlp_dim=3072,\n",
    "#     num_heads=12,\n",
    "#     pos_embed=\"perceptron\",\n",
    "#     norm_name=\"instance\",\n",
    "#     res_block=True,\n",
    "#     dropout_rate=0.0,\n",
    "# ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7f862a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load(os.path.join(\"/home/user/Documents/unetr\", \"unetr_fold4_best_metric_model.pth\")))\n",
    "# model.load_state_dict(torch.load(os.path.join(\"/home/user/Documents/swin_unetr/swin_unetr_model\", \"swinunetr_fold4_best_metric_model.pth\")))\n",
    "model.load_state_dict(torch.load(os.path.join(\"/media/user/2tb/model/unet_model\", \"unetfold4_best_metric_model.pth\")))\n",
    "\n",
    "# model.load_state_dict(torch.load(os.path.join(\"/home/user/Documents/swin_unetr/swin_unetr_model\", \"swinunetr_fold1_best_metric_model.pth\")))\n",
    "model.eval()\n",
    "case_num=1\n",
    "# with torch.no_grad():\n",
    "# #     for case_num in range(0,114):\n",
    "#     img_name = os.path.split(test_ds[case_num][\"image\"].meta[\"filename_or_obj\"])[1]\n",
    "#     img = test_ds[case_num][\"image\"]\n",
    "#     test_inputs = torch.unsqueeze(img, 1).cuda()\n",
    "#     test_outputs = sliding_window_inference(test_inputs, (96, 96, 96), 4, model, overlap=0.8,sw_device=\"cuda\")\n",
    "#     test_outputs=torch.argmax(test_outputs, dim=1)\n",
    "# #     saver=NiftiSaver(output_dir='/home/user/Documents/unetr/research-contributions/UNETR/BTCV/dataset/datasetmajei/swinunetr_majei_output',output_ext=img_name)\n",
    "#     saver=NiftiSaver(output_dir='/home/user/Documents/unetr/research-contributions/UNETR/BTCV/dataset/datasetmajei',output_ext=img_name)\n",
    "#     saver.save(test_outputs\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for test_data in test_loader:\n",
    "#         test_inputs = test_data[\"image\"].to(device)\n",
    "#         test_data[\"pred\"] = sliding_window_inference(test_inputs, (96,96,96), 4, model)\n",
    "\n",
    "#         test_data = [post_transforms(i) for i in decollate_batch(test_data)]\n",
    "#         test_output = from_engine([\"pred\"])(test_data)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for test_data in test_loader:\n",
    "        test_inputs = test_data[\"image\"].to(device)\n",
    "        test_data[\"pred\"] = sliding_window_inference(test_inputs, (96,96,96), 4, model)\n",
    "\n",
    "        test_data = [post_transforms(i) for i in decollate_batch(test_data)]\n",
    "        test_output = from_engine([\"pred\"])(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1c8912",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
